{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pyspark","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting pyspark\n  Downloading pyspark-3.0.1.tar.gz (204.2 MB)\n\u001b[K     |████████████████████████████████| 204.2 MB 28 kB/s s eta 0:00:01\n\u001b[?25hCollecting py4j==0.10.9\n  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n\u001b[K     |████████████████████████████████| 198 kB 63.1 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.0.1-py2.py3-none-any.whl size=204612244 sha256=ca2eb81ac08d9c76b9138098f6091b03fff1a4c02d332c8d92c83248746f507a\n  Stored in directory: /root/.cache/pip/wheels/5e/34/fa/b37b5cef503fc5148b478b2495043ba61b079120b7ff379f9b\nSuccessfully built pyspark\nInstalling collected packages: py4j, pyspark\nSuccessfully installed py4j-0.10.9 pyspark-3.0.1\n","name":"stdout"}]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from pyspark.sql.types import *\nfrom pyspark.sql.functions import *\nfrom pyspark.sql import SparkSession\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.stat import Correlation\nfrom pyspark.mllib.stat import Statistics\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer\nfrom pyspark.sql.types import StringType, DoubleType, IntegerType\nspark = SparkSession.builder.master(\"local[*]\").getOrCreate()","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = spark.read.csv(\"../input/home-credit-default-risk/application_train.csv\",inferSchema=\"true\", header=\"true\")","execution_count":4,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'spark' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-1a3aafd40737>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/home-credit-default-risk/application_train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minferSchema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"true\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"]}]},{"metadata":{},"cell_type":"markdown","source":"# Create Correlation heatmap"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sort out numerical columns\ndouble_cols = [f.name for f in df_train.schema.fields if isinstance(f.dataType, DoubleType)]\nint_cols = [f.name for f in df_train.schema.fields if isinstance(f.dataType, IntegerType)]\nnum_cols = int_cols+double_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert to vector column first\nvector_col = \"corr_features\"\nassembler = VectorAssembler(inputCols=num_cols, outputCol=vector_col)\ndf_vector = assembler.setHandleInvalid(\"skip\").transform(df_train).select(vector_col)\n\n# get correlation matrix\nmatrix = Correlation.corr(df_vector, vector_col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix = matrix.collect()[0][0]\ncorrmatrix = matrix.toArray().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(50,50))\nsns.heatmap(corrmatrix)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Apply OneHotEncoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sort out categorical columns\nstr_cols = [f.name for f in df_train.schema.fields if isinstance(f.dataType, StringType)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stages = []\nfor categoricalCol in str_cols:\n    #create a string indexer for those categorical values and assign a new name including the word 'Index'\n    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n\n    #append the string Indexer to our list of stages\n    stages += [stringIndexer]\n\n#Create the pipeline. Assign the satges list to the pipeline key word stages\npipeline = Pipeline(stages = stages)\n#fit the pipeline to our dataframe\npipelineModel = pipeline.fit(df_train)\n#transform the dataframe\ndf= pipelineModel.transform(df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create input columns and output columns\nstr_cols_index = []\nstr_cols_vec = []\nfor categoricalCol in str_cols:\n    str_cols_index.append(categoricalCol + 'Index')\n    str_cols_vec.append(categoricalCol + 'vec')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = OneHotEncoder(inputCols=str_cols_index,\n                        outputCols=str_cols_vec)\nmodel = encoder.fit(df)\nencoded = model.transform(df)\nencoded.columns\n#Not yet complete","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}